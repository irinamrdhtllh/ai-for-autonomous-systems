{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db5ca35f",
   "metadata": {},
   "source": [
    "# Week 4b - Model Evaluation (24/09/2025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5991205d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86601b38",
   "metadata": {},
   "source": [
    "## Previous class: CNN for image classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f29812e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.ToTensor()\n",
    "\n",
    "train_data = datasets.MNIST(root=\"./data\", train=True, download=False, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6dd1524",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)  # Flattening\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "824eaaf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss = 0.1210\n",
      "Epoch 2, Loss = 0.0643\n",
      "Epoch 3, Loss = 0.0533\n",
      "Epoch 4, Loss = 0.0473\n",
      "Epoch 5, Loss = 0.0421\n",
      "Epoch 6, Loss = 0.0411\n",
      "Epoch 7, Loss = 0.0385\n",
      "Epoch 8, Loss = 0.0379\n",
      "Epoch 9, Loss = 0.0414\n",
      "Epoch 10, Loss = 0.0405\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = CNN().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        preds = model(images)\n",
    "        loss = criterion(preds, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the weights and biases\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss = {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "893ce0c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Test Accuracy: 98.420\n"
     ]
    }
   ],
   "source": [
    "test_data = datasets.MNIST(root=\"./data\", train=False, download=False, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=8, shuffle=False)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "test_loss = 0\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "test_acc = (correct / total) * 100\n",
    "\n",
    "print(f\"\\nFinal Test Accuracy: {test_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a64734fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "# Get the first 5 test images and labels\n",
    "images, labels = next(iter(test_loader))\n",
    "\n",
    "images = images.to(device)\n",
    "labels = labels.to(device)\n",
    "\n",
    "# Get predictions\n",
    "with torch.no_grad():\n",
    "    outputs = model(images)\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "for i in range(5):\n",
    "    plt.subplot(1, 5, i + 1)\n",
    "    plt.imshow(images[i].cpu().squeeze(), cmap=\"gray\")\n",
    "    plt.title(f\"True: {labels[i].item()}\\nPred: {preds[i].item()}\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85fdd5d",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "949f839c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64aa79b",
   "metadata": {},
   "source": [
    "#### Using example y_true and y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96eb36b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 0, 0],\n",
       "       [1, 0, 1],\n",
       "       [0, 1, 2]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = [0, 1, 2, 2, 0, 1, 2]\n",
    "y_pred = [0, 0, 2, 2, 0, 2, 1]\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c75b6c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5714\n",
      "Precision: 0.4444\n",
      "Recall: 0.5556\n",
      "F1 Score: 0.4889\n"
     ]
    }
   ],
   "source": [
    "# Metrics\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "prec = precision_score(y_true, y_pred, average=\"macro\")\n",
    "rec = recall_score(y_true, y_pred, average=\"macro\")\n",
    "f1 = f1_score(y_true, y_pred, average=\"macro\")\n",
    "\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall: {rec:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e446c894",
   "metadata": {},
   "source": [
    "#### Using y_true and y_pred from our MNIST classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb921ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(preds.cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91acf4ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 976,    1,    0,    0,    0,    1,    1,    0,    0,    1],\n",
       "       [   0, 1127,    3,    1,    0,    3,    1,    0,    0,    0],\n",
       "       [   1,    0, 1016,    3,    0,    0,    0,   10,    2,    0],\n",
       "       [   0,    0,    2,  992,    0,   10,    0,    3,    3,    0],\n",
       "       [   0,    0,    1,    0,  969,    0,    4,    1,    0,    7],\n",
       "       [   4,    0,    0,    2,    0,  882,    2,    1,    0,    1],\n",
       "       [   4,    2,    1,    0,    1,    4,  945,    0,    1,    0],\n",
       "       [   0,    4,    8,    1,    2,    0,    0, 1005,    0,    8],\n",
       "       [   2,    1,    4,    1,    1,    6,    3,    0,  952,    4],\n",
       "       [   4,    0,    1,    0,    7,    9,    1,    7,    2,  978]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_true, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63906c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9842\n",
      "Precision: 0.9840\n",
      "Recall: 0.9842\n",
      "F1 Score: 0.9841\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(y_true, y_pred)\n",
    "prec = precision_score(y_true, y_pred, average=\"macro\")\n",
    "rec = recall_score(y_true, y_pred, average=\"macro\")\n",
    "f1 = f1_score(y_true, y_pred, average=\"macro\")\n",
    "\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall: {rec:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a947f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       980\n",
      "           1       0.99      0.99      0.99      1135\n",
      "           2       0.98      0.98      0.98      1032\n",
      "           3       0.99      0.98      0.99      1010\n",
      "           4       0.99      0.99      0.99       982\n",
      "           5       0.96      0.99      0.98       892\n",
      "           6       0.99      0.99      0.99       958\n",
      "           7       0.98      0.98      0.98      1028\n",
      "           8       0.99      0.98      0.98       974\n",
      "           9       0.98      0.97      0.97      1009\n",
      "\n",
      "    accuracy                           0.98     10000\n",
      "   macro avg       0.98      0.98      0.98     10000\n",
      "weighted avg       0.98      0.98      0.98     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(y_true, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d94aec",
   "metadata": {},
   "source": [
    "## How to improve a model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a342055d",
   "metadata": {},
   "source": [
    "#### Using batch size > 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2024d3b2",
   "metadata": {},
   "source": [
    "##### Example: Batch size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "446e6771",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d65c66e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss = 0.1041\n",
      "Epoch 2, Loss = 0.0402\n",
      "Epoch 3, Loss = 0.0275\n",
      "Epoch 4, Loss = 0.0218\n",
      "Epoch 5, Loss = 0.0176\n",
      "Epoch 6, Loss = 0.0155\n",
      "Epoch 7, Loss = 0.0139\n",
      "Epoch 8, Loss = 0.0118\n",
      "Epoch 9, Loss = 0.0125\n",
      "Epoch 10, Loss = 0.0123\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = CNN().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        preds = model(images)\n",
    "        loss = criterion(preds, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the weights and biases\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss = {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef13b573",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(preds.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "667f7f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9895\n",
      "Precision: 0.9894\n",
      "Recall: 0.9895\n",
      "F1 Score: 0.9894\n"
     ]
    }
   ],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "prec = precision_score(y_true, y_pred, average=\"macro\")\n",
    "rec = recall_score(y_true, y_pred, average=\"macro\")\n",
    "f1 = f1_score(y_true, y_pred, average=\"macro\")\n",
    "\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall: {rec:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c971811",
   "metadata": {},
   "source": [
    "##### Example: Batch size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "456f5f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b686c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss = 0.1096\n",
      "Epoch 2, Loss = 0.0415\n",
      "Epoch 3, Loss = 0.0280\n",
      "Epoch 4, Loss = 0.0202\n",
      "Epoch 5, Loss = 0.0162\n",
      "Epoch 6, Loss = 0.0128\n",
      "Epoch 7, Loss = 0.0102\n",
      "Epoch 8, Loss = 0.0108\n",
      "Epoch 9, Loss = 0.0091\n",
      "Epoch 10, Loss = 0.0078\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = CNN().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        preds = model(images)\n",
    "        loss = criterion(preds, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the weights and biases\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss = {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d75f9eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9919\n",
      "Precision: 0.9918\n",
      "Recall: 0.9918\n",
      "F1 Score: 0.9918\n"
     ]
    }
   ],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "prec = precision_score(y_true, y_pred, average=\"macro\")\n",
    "rec = recall_score(y_true, y_pred, average=\"macro\")\n",
    "f1 = f1_score(y_true, y_pred, average=\"macro\")\n",
    "\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall: {rec:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdf2252",
   "metadata": {},
   "source": [
    "#### Using dropout layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "766502c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNDropout(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNDropout, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.dropout1 = nn.Dropout(p=0.2)\n",
    "        self.dropout2 = nn.Dropout(p=0.5)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = x.view(x.size(0), -1)  # Flattening\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0be561f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss = 0.2130\n",
      "Epoch 2, Loss = 0.0988\n",
      "Epoch 3, Loss = 0.0761\n",
      "Epoch 4, Loss = 0.0654\n",
      "Epoch 5, Loss = 0.0571\n",
      "Epoch 6, Loss = 0.0533\n",
      "Epoch 7, Loss = 0.0491\n",
      "Epoch 8, Loss = 0.0459\n",
      "Epoch 9, Loss = 0.0438\n",
      "Epoch 10, Loss = 0.0401\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=8, shuffle=True)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = CNNDropout().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        preds = model(images)\n",
    "        loss = criterion(preds, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the weights and biases\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss = {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a8ffe4ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9918\n",
      "Precision: 0.9918\n",
      "Recall: 0.9917\n",
      "F1 Score: 0.9917\n"
     ]
    }
   ],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "prec = precision_score(y_true, y_pred, average=\"macro\")\n",
    "rec = recall_score(y_true, y_pred, average=\"macro\")\n",
    "f1 = f1_score(y_true, y_pred, average=\"macro\")\n",
    "\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall: {rec:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d62e393",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
